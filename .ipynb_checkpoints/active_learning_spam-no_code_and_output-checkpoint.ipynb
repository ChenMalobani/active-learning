{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Spam in SMS Using Active Learning\n",
    "\n",
    "## Dr. Omri Allouche \n",
    "(omri.allouche@gmail.com)\n",
    "\n",
    "This notebook is the 2nd and final part in a series analyzing the effect of Active Learning on classification tasks.\n",
    "\n",
    "In the previous notebook, we've used the MNIST dataset.  \n",
    "In this notebook, we'll use a dataset labeling SMS as spam/ham.  \n",
    "The dataset is available for download at http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:47.628607Z",
     "start_time": "2018-05-27T03:23:46.799593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.xkcd()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (48,20)\n",
    "# plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams[\"axes.titlesize\"] = 28\n",
    "plt.rcParams[\"axes.labelsize\"] = 24\n",
    "# plt.rcParams[\"figure.titlesize\"] = 50\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:47.634612Z",
     "start_time": "2018-05-27T03:23:47.630593Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:47.691656Z",
     "start_time": "2018-05-27T03:23:47.636612Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Let's first load the data. We'll use a dataset of ~5,300 text messages.  \n",
    "Each row contains the text of the message and its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:47.722593Z",
     "start_time": "2018-05-27T03:23:47.693596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data into a DataFrame\n",
    "df = pd.read_table('SMSSpamCollection', names=['y', 'text'])\n",
    "df = df.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:47.761592Z",
     "start_time": "2018-05-27T03:23:47.725593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's get basic summary statistics\n",
    "df.groupby('y').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing a basic Classifier\n",
    "Let's build a simple classifier.  \n",
    "We first split our data into train (80%) and test (20%) sets.  \n",
    "\n",
    "Our model will perform the following steps:\n",
    "1. Remove stopwords\n",
    "1. Count word occurrences\n",
    "1. Perform Tf-Idf transformation on counts\n",
    "1. Use a Multinomial Naive-Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:47.780591Z",
     "start_time": "2018-05-27T03:23:47.763592Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split data to train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['y'], test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:47.798595Z",
     "start_time": "2018-05-27T03:23:47.782592Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit the model to the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:47.892592Z",
     "start_time": "2018-05-27T03:23:47.802596Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the classification report for the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:47.997590Z",
     "start_time": "2018-05-27T03:23:47.894594Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:48.026594Z",
     "start_time": "2018-05-27T03:23:47.999593Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the f1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:48.055593Z",
     "start_time": "2018-05-27T03:23:48.029596Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot model confidence\n",
    "Let's plot the confidence level of our model for different samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:48.419592Z",
     "start_time": "2018-05-27T03:23:48.057593Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that while the model is very confident for most of the samples, there are about 100 samples (~10%) with low confidence.  \n",
    "\n",
    "Note that we define confidence as the prediction probability of the predicted class.  \n",
    "Since there are only 2 classes, the minimal value of confidence in this case is 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's review some of examples that got the lowest confidence.  \n",
    "We can see that in many of these cases, our model misclassifies them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:48.449590Z",
     "start_time": "2018-05-27T03:23:48.421594Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the model confidence correlated with its performance?\n",
    "Now, let's examine the model's performance as a function of its confidence (ie the probability it assigns to the predicted class).  \n",
    "We first get predictions on the test set, and save whether they are correct or not.  \n",
    "We then use Seaborn's `regplot` to plot average performance, using `x_bins=20`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:49.238590Z",
     "start_time": "2018-05-27T03:23:48.450590Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our model is pretty aware of its performance - it performs well when its confidence is high, and makes more mistakes when his confidence is low.\n",
    "\n",
    "This serves as a trigger for Active Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve\n",
    "Let's plot the learning curve of the classifier - its performance based on the number of samples labeled.  \n",
    "\n",
    "Each time, we take a subset of the train dataset, and use only it to train the model.  \n",
    "We then calculate performance on the test set (that's left intact).  \n",
    "We append the results of each run into a `history` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a function `def learning_curve(model, train_set_size_list, X_train, y_train, X_test, y_test)` and use it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:49.252593Z",
     "start_time": "2018-05-27T03:23:49.240593Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next calculate the learning curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:51.964862Z",
     "start_time": "2018-05-27T03:23:49.254592Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot the learning curve with the f1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:52.334843Z",
     "start_time": "2018-05-27T03:23:51.966821Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Active Learning\n",
    "Let's compare this to an Active Learning algorithm.  \n",
    "We first create a dataframe `df` with columns 'X', 'y' and content from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:52.403826Z",
     "start_time": "2018-05-27T03:23:52.336822Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we define the function `run_active_learner(df, model, num_samples_in_active_learning_batch, select_next_batch_func)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:52.451839Z",
     "start_time": "2018-05-27T03:23:52.405823Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the function `select_next_batch_func` for selecting the next batch for labeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:23:52.466839Z",
     "start_time": "2018-05-27T03:23:52.454823Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:24:36.290813Z",
     "start_time": "2018-05-27T03:23:52.469822Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_samples_in_active_learning_batch = [50] + [10]*150 + [25]*100\n",
    "al_history = run_active_learner(df, model, num_samples_in_active_learning_batch, select_next_batch_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot the models learning curve with and without active learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:24:36.711812Z",
     "start_time": "2018-05-27T03:24:36.292813Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using selected instances in a new model\n",
    "Next, let's check if the observations we asked to label based on the confidence of the Logistic Regression model are helpful for other models. We'll train a Logistic Regression model with L1 regularization.  \n",
    "We'll plot its learning curve for randomly selected samples along with the learning curve for observations that were chosen for labeling in our previous perceptron classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define a new pipeline for model2 using Logistic Regression with L1 regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:24:36.756835Z",
     "start_time": "2018-05-27T03:24:36.713799Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:24:39.610807Z",
     "start_time": "2018-05-27T03:24:36.758813Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set_size_list = [10,20,30,40] + list(np.arange(50,500,20)) + list(np.arange(500,4000,100))\n",
    "history_logistic_regression = learning_curve(model2, train_set_size_list, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:24:39.982792Z",
     "start_time": "2018-05-27T03:24:39.612796Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the function `run_active_learner_with_different_model(df, model, model2, num_samples_in_active_learning_batch, select_next_batch_func)` that also computes the accuracy and f1 on the test set when model2 is fitted to the labeled instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:24:40.033793Z",
     "start_time": "2018-05-27T03:24:39.984794Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:25:37.124859Z",
     "start_time": "2018-05-27T03:24:40.035808Z"
    }
   },
   "outputs": [],
   "source": [
    "num_samples_in_active_learning_batch = [50] + [10]*150 + [25]*100\n",
    "# num_samples_in_active_learning_batch = [50] + [10]*150\n",
    "\n",
    "al_history_model2 = run_active_learner_with_different_model(df, model, model2, num_samples_in_active_learning_batch, select_next_batch_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:25:37.559803Z",
     "start_time": "2018-05-27T03:25:37.126808Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstraping Results\n",
    "Let's try a cycle (or more) of bootstraping - we'll use predictions with high confidence of the model as \"ground truth\" for another round of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:25:37.631835Z",
     "start_time": "2018-05-27T03:25:37.561794Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:30:01.156629Z",
     "start_time": "2018-05-27T03:29:50.510595Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_samples_in_active_learning_batch = [100] + [10]*30\n",
    "# al_history = run_active_learner(df, model, num_samples_in_active_learning_batch, select_next_batch_func)\n",
    "al_history_bootstrap_1 = run_active_learner_with_bootstrap(df, model, num_samples_in_active_learning_batch, select_next_batch_func, bootstrap=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T03:30:01.602141Z",
     "start_time": "2018-05-27T03:30:01.158588Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
